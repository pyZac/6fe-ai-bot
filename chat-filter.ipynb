{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cb7cc05-d9c6-4826-9261-868604705130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import unicodedata\n",
    "import hashlib\n",
    "from difflib import SequenceMatcher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673c86a-5811-456a-b7f3-792de64cf61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AR_DIACRITICS = re.compile(r'[\\u0610-\\u061A\\u064B-\\u065F\\u0670\\u06D6-\\u06ED]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57d27660-1f69-4e82-8b0d-8e5ce9fdf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_RE = re.compile(r'https?://\\S+')\n",
    "\n",
    "def strip_urls(s: str) -> str:\n",
    "    return URL_RE.sub('', s).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe383abc-601d-4add-80c2-384ecdda2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_rules_announcement(text: str) -> bool:\n",
    "    \"\"\"ÙŠØ±Ø¬Ø¹ True Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø¥Ø¹Ù„Ø§Ù†/Ù‚ÙˆØ§Ù†ÙŠÙ†/ØªØ±Ø­ÙŠØ¨ Ø¹Ø§Ù…ØŒ ÙÙ†Ø³ØªØ«Ù†ÙŠÙ‡Ø§.\"\"\"\n",
    "    if not text:\n",
    "        return False\n",
    "\n",
    "    t  = strip_urls(text)\n",
    "    tn = normalize_ar(t)\n",
    "\n",
    "   \n",
    "    if \"Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ù‡\" in tn or \"Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„ØºØ±ÙˆØ¨\" in tn or \"Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¬Ø±ÙˆØ¨\" in tn:\n",
    "        return True\n",
    "    if \"Ø³ÙŠØªÙ… Ø­Ø°ÙÙƒ\" in tn or \"Ø³ÙŠØªÙ… Ø­Ø°ÙÙƒÙ…\" in tn:\n",
    "        return True\n",
    "\n",
    "  \n",
    "    dash_count = tn.count(\"-\") + tn.count(\"â€¢\") + tn.count(\"â€“\")\n",
    "    no_count   = tn.count(\"Ø¹Ø¯Ù…\")\n",
    "\n",
    "    if dash_count >= 5:\n",
    "        return True\n",
    "    if dash_count >= 3 and no_count >= 2:\n",
    "        return True\n",
    "\n",
    "    \n",
    "    if any(e in t for e in (\"ðŸ”ˆ\",\"ðŸ“¢\",\"ðŸ“£\",\"ðŸ“Œ\",\"âš ï¸\")) and (\"Ù‚ÙˆØ§Ù†ÙŠÙ†\" in tn or no_count >= 2):\n",
    "        return True\n",
    "\n",
    "   \n",
    "    if (\"Ø§Ù‡Ù„Ø§\" in tn or \"Ù…Ø±Ø­Ø¨Ø§\" in tn or \"ØªØ±Ø­ÙŠØ¨\" in tn) and (\"Ù‚ÙˆØ§Ù†ÙŠÙ†\" in tn or \"Ø§Ù„Ø§Ù„ØªØ²Ø§Ù…\" in tn):\n",
    "        return True\n",
    "\n",
    "\n",
    "    line_count = len([x for x in re.split(r\"\\s*\\n+\\s*\", t) if x.strip()])\n",
    "    if line_count >= 6 and (\"Ù‚ÙˆØ§Ù†ÙŠÙ†\" in tn or no_count >= 2 or dash_count >= 3):\n",
    "        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08967079-09e8-4ef9-8cc7-8704160facbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MENTION_RE = re.compile(r'@[\\w\\d_]+')\n",
    "MULTISPACE_RE = re.compile(r'\\s+')\n",
    "\n",
    "def normalize_answer_text(s: str) -> str:\n",
    "    \"\"\"ØªØ·Ø¨ÙŠØ¹ Ù†Øµ Ø§Ù„Ø¬ÙˆØ§Ø¨ Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©/Ø§Ù„Ù‡Ø§Ø´.\"\"\"\n",
    "    s = strip_urls(s or '')\n",
    "    s = MENTION_RE.sub('', s)\n",
    "    s = normalize_ar(s)           \n",
    "    s = s.lower()\n",
    "    s = MULTISPACE_RE.sub(' ', s).strip()\n",
    "    return s\n",
    "\n",
    "def text_hash(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode('utf-8')).hexdigest()\n",
    "\n",
    "class TextDeduper:\n",
    "    def __init__(self, sim_threshold: float = 0.90, approx_window: int = 200):\n",
    "        self.sim_threshold = sim_threshold\n",
    "        self.approx_window = approx_window\n",
    "        self._seen_hashes = set()\n",
    "        self._recent_norm_texts = []  \n",
    "\n",
    "    def is_duplicate(self, text: str):\n",
    "        \"\"\"ÙŠØ±Ø¬Ø¹ (is_dup: bool, matched_norm: str | None)\"\"\"\n",
    "        n = normalize_answer_text(text)\n",
    "        if not n:\n",
    "            return False, None  \n",
    "        h = text_hash(n)\n",
    "        if h in self._seen_hashes:\n",
    "            return True, n \n",
    "\n",
    "        \n",
    "        for cand in reversed(self._recent_norm_texts[-self.approx_window:]):\n",
    "            if len(cand) < 12 and len(n) < 12:\n",
    "                \n",
    "                ratio = SequenceMatcher(a=cand, b=n).ratio()\n",
    "                if ratio >= max(self.sim_threshold, 0.95):\n",
    "                    return True, cand\n",
    "            else:\n",
    "                ratio = SequenceMatcher(a=cand, b=n).ratio()\n",
    "                if ratio >= self.sim_threshold:\n",
    "                    return True, cand\n",
    "\n",
    "        return False, None\n",
    "\n",
    "    def add(self, text: str):\n",
    "        \"\"\"ÙŠØ­Ø§ÙˆÙ„ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ. ÙŠØ±Ø¬Ø¹ (added: bool, norm_text: str).\"\"\"\n",
    "        n = normalize_answer_text(text)\n",
    "        if not n:\n",
    "            return False, n\n",
    "        h = text_hash(n)\n",
    "        if h in self._seen_hashes:\n",
    "            return False, n\n",
    "      \n",
    "        is_dup, _ = self.is_duplicate(text)\n",
    "        if is_dup:\n",
    "            return False, n\n",
    "      \n",
    "        self._seen_hashes.add(h)\n",
    "        self._recent_norm_texts.append(n)\n",
    "        return True, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff54f76-2b67-499e-acc9-42e4804c19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_deduper = TextDeduper(sim_threshold=0.90, approx_window=200)\n",
    "\n",
    "def collect_answers_for_question(messages_after_q):\n",
    "    local_deduper  = TextDeduper(sim_threshold=0.90, approx_window=100)\n",
    "    unique_answers = []\n",
    "\n",
    "    for msg in messages_after_q:\n",
    "        ans_text = msg.get(\"text\")  \n",
    "  \n",
    "\n",
    "    \n",
    "        added_local, _ = local_deduper.add(ans_text)\n",
    "        if not added_local:\n",
    "            continue\n",
    "\n",
    "  \n",
    "        added_global, _ = global_deduper.add(ans_text)\n",
    "        if not added_global:\n",
    "            continue\n",
    "\n",
    "        unique_answers.append(ans_text)\n",
    "\n",
    "    return unique_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dde60-c2ff-4d8f-90d4-70f7b8238cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ar(s: str) -> str:\n",
    "    s = (s or '').strip()\n",
    "\n",
    "    s = s.replace(\"Ø£\",\"Ø§\").replace(\"Ø¥\",\"Ø§\").replace(\"Ø¢\",\"Ø§\")\n",
    "\n",
    "    s = s.replace(\"Ù‰\",\"ÙŠ\").replace(\"Ø©\",\"Ù‡\")\n",
    "\n",
    "    s = AR_DIACRITICS.sub(\"\", s)\n",
    "\n",
    "    s = s.replace(\"Ù€\", \"\")\n",
    "\n",
    "    s = re.sub(r\"[^\\w\\s]\", \" \", s)\n",
    "\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e95d4-0b6e-426b-9f2a-c428b53ae56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(t: str) -> str:\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = \" \".join(t.split())\n",
    "\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0f88ac1-4e6a-4dfc-a3dd-a172b5386568",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_meaningful(text):\n",
    "    if not text:\n",
    "        return False\n",
    "    if len(text) < 4:\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ca62f-6725-4d29-94e9-0bab750a9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sender_bonus(sender: str) -> int:\n",
    "    s = (sender or \"\").strip().lower()\n",
    "   \n",
    "    return 10 if s == \"saher\" else 0\n",
    "\n",
    "def compute_qscore(msg: dict) -> int:\n",
    "    base = question_score(msg.get(\"text\", \"\"))\n",
    "    return min(100, base + sender_bonus(msg.get(\"sender\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79657b7-5ed1-4a7d-8904-1fe3df622ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ù‚ÙˆØ§Ø¦Ù… Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª\n",
    "AR_Q_START = (\"ÙƒÙŠÙ\",\"Ø´Ùˆ ÙŠØ¹Ù†ÙŠ\",\"Ù…Ø§Ø°Ø§\",\"Ù„ÙŠØ´\",\"Ù„Ù…Ø§Ø°Ø§\",\"Ù‡Ù„\",\"Ù…ØªÙ‰\",\"Ø£ÙŠÙ†\",\"ÙƒÙ…\",\"Ø´Ù„ÙˆÙ†\",\"Ø§ÙŠØ´\",\"Ø´Ù†Ùˆ\",\"ÙÙ„ÙŠØ´\",\"Ø£ÙŠÙ…Øª\",\"Ø³Ø¤Ø§Ù„\",\"Ø³ÙˆØ§Ù„\")\n",
    "\n",
    "AR_Q_PHRASES = (\"Ø´Ùˆ Ø±Ø§ÙŠÙƒÙ…\",\"Ø§ÙŠÙ‡ Ø±Ø§ÙŠÙƒÙ…\",\"Ù…Ø§ Ø±Ø§ÙŠÙƒÙ…\",\"Ø´Ùˆ Ø±Ø§ÙŠÙƒ\",\"Ø§ÙŠÙ‡ Ø±Ø§ÙŠÙƒ\",\"Ø¨ÙØ¶Ù„\",\"Ø±ÙƒØ²\",\"ÙƒÙˆØªØ´\",\"ÙŠÙØ¶Ù„\",\"Ù†Ø¨Ù‡Ùƒ\")\n",
    "\n",
    "IMP_WORDS = (\"Ø§Ù…Ø´ÙŠ\",\"Ù…Ø§ ØªØ¹Ø§ÙƒØ³\",\"Ù…Ø§ ØªØ¹Ø§ÙƒØ³ÙˆØ§\",\"Ø£Ù‡Ù…\",\"Ø£ÙØ¶Ù„\",\"Ø®Ø·Ø£\",\"Ù…Ù…Ù†ÙˆØ¹\",\"ÙˆØ­Ø´\",\"Ù†ØµÙŠØ­ØªÙŠ\"\n",
    "             ,\"Ø§Ù†ØµØ­Ùƒ\",\"Ù†ØµÙŠØ­Ø©\",\"Ø¨Ø±Ø§ÙÙˆ\",\"Ø§Ø­Ø³Ø¨Ùˆ\",\"Ø§Ø­Ø³Ø¨ÙˆØ§\",\"Ù…Ù‡Ù…\",\"Ù…Ù‡Ù…Ø©\",\"Ø§Ù„Ø·Ù…Ø¹\",\"Ø§Ø³ØªÙ†Ùˆ\",\"Ø§Ø³ØªÙ†ÙˆØ§\"\n",
    "             ,\"Ø¨ØªÙ„Ø§Ø­Ø¸Ùˆ\",\"Ø¨ØªÙ„Ø§Ø­Ø¸Ùˆ\",\"Ø¯Ø±Ø³\",\"ØºÙ„Ø·ÙŠ\",\"Ø³ØªÙ†Ùˆ\",\"Ø¨ØªØ¹ÙˆØ¶\",\"ØªØ­Ø°ÙŠØ±\",\"Ø±Ø§Ø­Ø©\",\"Ù†ÙØ³ÙŠØ©\",\"Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª\",\"Ø¨ØªØ§Ø«Ø±\"\n",
    "             ,\"Ø®Ø·Ø©\",\"Ø§Ø­ÙØ¸ÙŠ\",\"Ø§Ù„Ø¯Ø±Ø³\",\"Ù†Ø¯Ù…Ø§Ù†\",\"Ø¹Ù„Ù…Ù†ÙŠ\",\"Ø£Ù…ÙˆØ±Ùƒ ØªÙ…Ø§Ù…\",\"Ù„Ø§ØªÙ…Ø´ÙŠ\",\"Ø®Ù„ÙŠ\",\"Ù…Ø³ØªÙˆØ§ÙŠ\",\"Ø¶Ø¯\",\"Ø§Ù„ØªØ²Ù…\",\"Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø©\",\"Ù‚Ø§Ø¹Ø¯Ø©\",\"Ø´ÙØªÙˆ\",\"Ù†ÙˆÙ‡\",\"Ø§Ø¯Ø®Ù„\",\"Ø­Ø§Ø¨Ø¨\",\"ØªØ±ÙŠØ¯Ù†Øº\")\n",
    "\n",
    "DOMAIN_WORD = (\"Ø±Ø§Ø³Ù…Ø§Ù„Ùƒ\",\"Ø±Ø£Ø³Ù…Ø§Ù„\",\"Ø°ÙŠÙ„\",\"Ù‚Ù…Ø©\",\"Ù…Ù‚Ø§ÙˆÙ…Ø©\",\"Ø¯Ø¹Ù…\",\"ÙØ±ÙŠÙ…\",\"ØªØ´Ø§Ø±Øª\",\"Ø´Ø§Ø±Øª\",\n",
    "               \"ØªØ­Ù„ÙŠÙ„\",\"Ø³ÙˆÙŠÙ†Øº\",\"ØµÙÙ‚Ø©\",\"Ø³ÙƒØ§Ù„Ø¨ÙŠÙ†Øº\",\"Ø§Ù„ÙØ±ÙŠÙ…\",\"Ø§Ù„ØªØ±Ù†Ø¯\",\"ØªØ±Ù†Ø¯\",\"Ø±Ø£Ø³ Ù…Ø§Ù„\",\"Ø°Ù‡Ø¨\",\"Ø¯Ù‡Ø¨\",\"Ø³ØªÙˆØ¨\",\"Ù‡Ø¯Ù\",\"Ø§Ù„ØªØ¯Ø§ÙˆÙ„\",\"ØµÙÙ‚Ø§Øª\",\"Ø¨ÙŠØ¹\",\"Ø§Ù„Ø¹Ø§Ù…Ù„ Ø§Ù„Ù†ÙØ³ÙŠ\")\n",
    "\n",
    "\n",
    "AR_Q_START_N   = set(normalize_ar(w) for w in AR_Q_START)\n",
    "AR_Q_PHRASES_N = tuple(normalize_ar(p) for p in AR_Q_PHRASES)\n",
    "IMP_WORDS_N    = set(normalize_ar(w) for w in IMP_WORDS)\n",
    "DOMAIN_WORD_N  = tuple(normalize_ar(w) for w in DOMAIN_WORD)\n",
    "\n",
    "URL_RE = re.compile(r'https?://\\S+')\n",
    "TOKEN_SPLIT_RE = re.compile(r\"[^\\w\\u0600-\\u06FF]+\", flags=re.UNICODE)  # ÙØ§ØµÙ„Ø§Øª/Ù…Ø³Ø§ÙØ§Øª/Ø±Ù…ÙˆØ²\n",
    "\n",
    "def strip_urls(s: str) -> str:\n",
    "    return URL_RE.sub('', s or '').strip()\n",
    "\n",
    "\n",
    "\n",
    "def split_tokens(tn: str):\n",
    "    toks = tn.split()\n",
    "    return toks\n",
    "\n",
    "def question_score(text: str) -> int:\n",
    "    if not text:\n",
    "        return 0\n",
    "\n",
    "    t  = strip_urls(text)\n",
    "    tn = normalize_ar(t)\n",
    "\n",
    "\n",
    "    if is_rules_announcement(text):\n",
    "        return 0\n",
    "\n",
    "    score = 0\n",
    "\n",
    "\n",
    "    if \"?\" in t or \"ØŸ\" in t:\n",
    "        score += 10\n",
    "\n",
    "\n",
    "    tokens    = split_tokens(tn)\n",
    "    token_set = set(tokens)\n",
    "\n",
    "\n",
    "    if token_set.intersection(AR_Q_START_N):\n",
    "        score += 15\n",
    "\n",
    "\n",
    "    if any(phrase in tn for phrase in AR_Q_PHRASES_N):\n",
    "        score += 15\n",
    "\n",
    "\n",
    "    if token_set.intersection(IMP_WORDS_N):\n",
    "        score += 40\n",
    "\n",
    "\n",
    "    dom_unique = set()\n",
    "    for w in DOMAIN_WORD_N:\n",
    "        if \" \" in w:\n",
    "            if w in tn:\n",
    "                dom_unique.add(w)\n",
    "        else:\n",
    "            if w in token_set:\n",
    "                dom_unique.add(w)\n",
    "\n",
    "    if len(dom_unique) >= 2:\n",
    "        score += 40\n",
    "    elif len(dom_unique) == 1:\n",
    "        score += 20\n",
    "\n",
    "\n",
    "    letters_only = re.sub(r\"\\W+\", \"\", tn, flags=re.UNICODE)\n",
    "    if len(letters_only) < 8:\n",
    "        score -= 20\n",
    "    if len(letters_only) == 0 and len(tn) > 0:\n",
    "        score -= 20\n",
    "\n",
    "    return max(0, min(100, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "751ae7a9-2d32-48fa-a89c-761fd751803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_question(text: str, threshold: int = 40) -> bool:\n",
    "    return question_score(text) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaa64f-37cc-4163-a4d9-2cf9bc59a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_messages_simple(html_file):\n",
    "    with open(html_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f.read(), \"html.parser\")\n",
    "\n",
    "    all_blocks = soup.find_all(\"div\", class_=True)\n",
    "\n",
    "    messages = []\n",
    "    current_date = None\n",
    "    last_sender = None\n",
    "\n",
    "    for blk in all_blocks:\n",
    "        classes = blk.get(\"class\", [])\n",
    "\n",
    "        if not ((\"message\" in classes) or (\"pull_right\" in classes)):\n",
    "            continue\n",
    "\n",
    "\n",
    "        if \"date\" in classes:\n",
    "            #body = blk.find(\"div\", class_=\"body\") or blk.find(\"div\", class_=lambda c: c and \"body\" in c)\n",
    "            body = blk.get(\"title\", \"\")\n",
    "\n",
    "            if body:\n",
    "                txt = clean_text(body)\n",
    "                if txt:\n",
    "                    current_date = txt[0:10]\n",
    "                    #print(current_date[0:10])\n",
    "            continue\n",
    "\n",
    "\n",
    "        body = blk.find(\"div\", class_=\"body\") or blk.find(\"div\", class_=lambda c: c and \"body\" in c)\n",
    "        if not body:\n",
    "            continue\n",
    "\n",
    "        from_name_el = body.find(\"div\", class_=\"from_name\") or body.find(\"div\", class_=lambda c: c and \"from_name\" in c)\n",
    "        if from_name_el:\n",
    "            sender = clean_text(from_name_el.get_text(\" \", strip=True))\n",
    "            last_sender = sender\n",
    "        else:\n",
    "            sender = last_sender or \"unknown\"\n",
    "\n",
    "        text_el = body.find(\"div\", class_=\"text\") or body.find(\"div\", class_=lambda c: c and \"text\" in c)\n",
    "        text = clean_text(text_el.get_text(\" \", strip=True)) if text_el else \"\"\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        tg_id = blk.get(\"id\", \"\")\n",
    "\n",
    "        messages.append({\n",
    "            \"tg_id\": tg_id,\n",
    "            \"date\": current_date,\n",
    "            \"sender\": sender,\n",
    "            \"text\": text,\n",
    "            \"   \" : \"   \"\n",
    "        })\n",
    "\n",
    "        if len(messages) >= 10000 : break\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83f349-54bc-4fc7-a43e-fa349fb1d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_deduper = TextDeduper(sim_threshold=0.90, approx_window=200)\n",
    "global_answer_owner = {}  \n",
    "\n",
    "def build_candidates_simple(\n",
    "    messages,\n",
    "    window_after: int = 5,\n",
    "    threshold: int = 40,\n",
    "    max_answers: int = 3,\n",
    "    min_answer_chars: int = 8,\n",
    "    require_answers: bool = True,\n",
    "    min_qscore_include_if_no_answers: int = 70, \n",
    "):\n",
    "    rows = []\n",
    "    seen_questions = set()\n",
    "\n",
    "    for i, m in enumerate(messages):\n",
    "      \n",
    "        if is_rules_announcement(m.get(\"text\", \"\")):\n",
    "            continue\n",
    "\n",
    "        qscore = compute_qscore(m)\n",
    "        if qscore < threshold:\n",
    "            continue\n",
    "\n",
    "        q_id = m.get(\"tg_id\") or f\"i{i}\"\n",
    "        if q_id in seen_questions:\n",
    "            continue\n",
    "        seen_questions.add(q_id)\n",
    "\n",
    "        q = m\n",
    "        candidates = []\n",
    "        local_deduper = TextDeduper(sim_threshold=0.90, approx_window=100)\n",
    "\n",
    "        j = i + 1\n",
    "        end = min(len(messages), i + 1 + window_after)\n",
    "        while j < end:\n",
    "            reply = messages[j]\n",
    "\n",
    "         \n",
    "            if is_rules_announcement(reply.get(\"text\", \"\")):\n",
    "                j += 1\n",
    "                continue\n",
    "\n",
    "            if compute_qscore(reply) >= threshold:\n",
    "                break\n",
    "\n",
    "            if reply.get(\"sender\") != q.get(\"sender\") and is_meaningful(reply.get(\"text\", \"\")):\n",
    "                raw = (reply.get(\"text\") or \"\").strip()\n",
    "                n = normalize_answer_text(raw)\n",
    "                if len(n) >= min_answer_chars:\n",
    "                    added_local, _ = local_deduper.add(raw)\n",
    "                    if not added_local:\n",
    "                        j += 1; continue\n",
    "                    added_global, ng = global_deduper.add(raw)\n",
    "                    if not added_global:\n",
    "                        j += 1; continue\n",
    "                    global_answer_owner.setdefault(ng, q_id)\n",
    "                    candidates.append(raw)\n",
    "                    if max_answers and len(candidates) >= max_answers:\n",
    "                        break\n",
    "            j += 1\n",
    "\n",
    "  \n",
    "        include_row = (\n",
    "            len(candidates) > 0\n",
    "            or not require_answers\n",
    "            or qscore >= min_qscore_include_if_no_answers\n",
    "        )\n",
    "\n",
    "        if include_row:\n",
    "            rows.append({\n",
    "                \"tg_msg_id\": q_id,\n",
    "                \"date\": q.get(\"date\") or \"\",\n",
    "                \"sender\": q.get(\"sender\") or \"\",\n",
    "                \"question_text\": q.get(\"text\") or \"\",\n",
    "                \"answer_candidates\": \" ||| \".join(candidates) if candidates else \"\",\n",
    "                \"q_score\": qscore,\n",
    "            })\n",
    "\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "558872b8-22e6-4e7b-99eb-cde48775ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    html_in = \"messages22.html\"\n",
    "    csv_out = \"candidates_simple22.csv\"\n",
    "\n",
    "    msgs = parse_messages_simple(html_in)\n",
    "    rows = build_candidates_simple(msgs, window_after=5)\n",
    "\n",
    "    with open(csv_out, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"tg_msg_id\", \"date\", \"sender\", \"question_text\", \"answer_candidates\",\"q_score\"])\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    print(\"Parsed messages:\", len(msgs))\n",
    "    print(\"Candidate questions found:\", len(rows))\n",
    "    print(\"Output CSV:\", csv_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83835bc1-a417-47b7-810f-ad1cd64aa108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed messages: 82\n",
      "Candidate questions found: 2\n",
      "Output CSV: candidates_simple22.csv\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b849e-c02f-4034-a276-79f8713ea7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3d993-5ce1-489d-bed3-f48ce7e22d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7190e1c1-a316-4596-ac46-b008a08fea11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
